{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0173a7f3-640f-40f0-abf7-9e2242e77350",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\trejan\\\\Desktop\\\\GenoneDataset\\\\nutrients\\\\train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m      7\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrejan\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mGenoneDataset\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mnutrients\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Display basic information\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\trejan\\\\Desktop\\\\GenoneDataset\\\\nutrients\\\\train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"C:\\\\Users\\\\trejan\\\\Desktop\\\\GenoneDataset\\\\nutrients\\\\train.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc36e94-3433-4e7c-aaa3-27fd87c4280f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6894 entries, 0 to 6893\n",
      "Data columns (total 41 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ID                6894 non-null   int64  \n",
      " 1   FoodGroup         6894 non-null   object \n",
      " 2   Descrip           6894 non-null   object \n",
      " 3   Energy_kcal       6894 non-null   float64\n",
      " 4   Protein_g         6894 non-null   float64\n",
      " 5   Fat_g             6894 non-null   float64\n",
      " 6   Carb_g            6894 non-null   float64\n",
      " 7   Sugar_g           6894 non-null   float64\n",
      " 8   Fiber_g           6894 non-null   float64\n",
      " 9   VitA_mcg          6894 non-null   float64\n",
      " 10  VitB6_mg          6894 non-null   float64\n",
      " 11  VitB12_mcg        6894 non-null   float64\n",
      " 12  VitC_mg           6894 non-null   float64\n",
      " 13  VitE_mg           6894 non-null   float64\n",
      " 14  Folate_mcg        6894 non-null   float64\n",
      " 15  Niacin_mg         6894 non-null   float64\n",
      " 16  Riboflavin_mg     6894 non-null   float64\n",
      " 17  Thiamin_mg        6894 non-null   float64\n",
      " 18  Calcium_mg        6894 non-null   float64\n",
      " 19  Copper_mcg        6894 non-null   float64\n",
      " 20  Iron_mg           6894 non-null   float64\n",
      " 21  Magnesium_mg      6894 non-null   float64\n",
      " 22  Manganese_mg      6894 non-null   float64\n",
      " 23  Phosphorus_mg     6894 non-null   float64\n",
      " 24  Selenium_mcg      6894 non-null   float64\n",
      " 25  Zinc_mg           6894 non-null   float64\n",
      " 26  VitA_USRDA        6894 non-null   float64\n",
      " 27  VitB6_USRDA       6894 non-null   float64\n",
      " 28  VitB12_USRDA      6894 non-null   float64\n",
      " 29  VitC_USRDA        6894 non-null   float64\n",
      " 30  VitE_USRDA        6894 non-null   float64\n",
      " 31  Folate_USRDA      6894 non-null   float64\n",
      " 32  Niacin_USRDA      6894 non-null   float64\n",
      " 33  Riboflavin_USRDA  6894 non-null   float64\n",
      " 34  Thiamin_USRDA     6894 non-null   float64\n",
      " 35  Calcium_USRDA     6894 non-null   float64\n",
      " 36  Copper_USRDA      6894 non-null   float64\n",
      " 37  Magnesium_USRDA   6894 non-null   float64\n",
      " 38  Phosphorus_USRDA  6894 non-null   float64\n",
      " 39  Selenium_USRDA    6894 non-null   float64\n",
      " 40  Zinc_USRDA        6894 non-null   float64\n",
      "dtypes: float64(38), int64(1), object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4346aff-2517-4e3e-8689-4d105bb413ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values Analysis:\n",
      "==================================================\n",
      "No missing values found in the dataset!\n",
      "\n",
      "Shape of Original Dataset: (6894, 41)\n",
      "Shape of Cleaned Dataset: (6894, 41)\n",
      "\n",
      "Sample of Cleaned Data:\n",
      "==================================================\n",
      "      ID                       FoodGroup  \\\n",
      "0  16116     Legumes and Legume Products   \n",
      "1  18316                  Baked Products   \n",
      "2  15261  Finfish and Shellfish Products   \n",
      "3   8417               Breakfast Cereals   \n",
      "4  20022         Cereal Grains and Pasta   \n",
      "\n",
      "                                             Descrip  Energy_kcal  Protein_g  \\\n",
      "0                       Soy flour, full-fat, roasted        441.0      34.80   \n",
      "1        Pie, coconut custard, commercially prepared        260.0       5.90   \n",
      "2                                 Fish, tilapia, raw         96.0      20.08   \n",
      "3  Cereals, QUAKER, Instant Oatmeal, Banana Bread...        368.0       8.97   \n",
      "4               Cornmeal, degermed, enriched, yellow        370.0       7.11   \n",
      "\n",
      "   Fat_g  Carb_g  Sugar_g  Fiber_g  VitA_mcg  ...  Folate_USRDA  Niacin_USRDA  \\\n",
      "0  21.86   33.67     7.61      9.7       6.0  ...        0.5675      0.205375   \n",
      "1  13.20   30.20     0.00      1.8      26.0  ...        0.0475      0.025188   \n",
      "2   1.70    0.00     0.00      0.0       0.0  ...        0.0600      0.243938   \n",
      "3   4.85   75.70    29.45      6.7       0.0  ...        0.0000      0.706875   \n",
      "4   1.75   79.45     1.61      3.9      11.0  ...        0.8375      0.310500   \n",
      "\n",
      "   Riboflavin_USRDA  Thiamin_USRDA  Calcium_USRDA  Copper_USRDA  \\\n",
      "0          0.723846       0.343333       0.156667      0.002468   \n",
      "1          0.113846       0.073333       0.067500      0.000070   \n",
      "2          0.048462       0.034167       0.008333      0.000083   \n",
      "3          0.769231       0.816667       0.230833      0.000000   \n",
      "4          0.293846       0.459167       0.002500      0.000084   \n",
      "\n",
      "   Magnesium_USRDA  Phosphorus_USRDA  Selenium_USRDA  Zinc_USRDA  \n",
      "0         0.878571          0.680000        0.136364    0.325455  \n",
      "1         0.042857          0.174286        0.116364    0.061818  \n",
      "2         0.064286          0.242857        0.760000    0.030000  \n",
      "3         0.219048          0.450000        0.000000    0.188182  \n",
      "4         0.076190          0.141429        0.190909    0.060000  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"C:\\\\Users\\\\trejan\\\\Desktop\\\\GenoneDataset\\\\nutrients\\\\train.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def analyze_and_handle_nulls(df):\n",
    "    \"\"\"\n",
    "    Analyze null values and handle them appropriately based on the nature of the data\n",
    "    \"\"\"\n",
    "    # Calculate percentage of missing values for each column\n",
    "    missing_percentages = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    print(\"\\nMissing Values Analysis:\")\n",
    "    print(\"=\"*50)\n",
    "    has_missing = False\n",
    "    for column in df.columns:\n",
    "        missing_count = df[column].isnull().sum()\n",
    "        missing_percent = missing_percentages[column]\n",
    "        if missing_count > 0:\n",
    "            has_missing = True\n",
    "            print(f\"{column}: {missing_count} missing values ({missing_percent:.2f}%)\")\n",
    "    \n",
    "    if not has_missing:\n",
    "        print(\"No missing values found in the dataset!\")\n",
    "        return df\n",
    "    \n",
    "    # Create a copy of the dataframe to handle missing values\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # Handle missing values based on the type of data and percentage missing\n",
    "    for column in df_cleaned.columns:\n",
    "        missing_percent = missing_percentages[column]\n",
    "        \n",
    "        if missing_percent == 0:\n",
    "            continue\n",
    "            \n",
    "        # For columns with numerical data\n",
    "        if df_cleaned[column].dtype in ['int64', 'float64']:\n",
    "            # If less than 5% missing, fill with median\n",
    "            if missing_percent < 5:\n",
    "                median_value = df_cleaned[column].median()\n",
    "                df_cleaned[column].fillna(median_value, inplace=True)\n",
    "                print(f\"\\nFilled {column} nulls with median: {median_value:.2f}\")\n",
    "            # If more than 5% missing, fill with median but flag the imputed values\n",
    "            else:\n",
    "                # Create a flag column for imputed values\n",
    "                df_cleaned[f'{column}_imputed'] = df_cleaned[column].isnull().astype(int)\n",
    "                median_value = df_cleaned[column].median()\n",
    "                df_cleaned[column].fillna(median_value, inplace=True)\n",
    "                print(f\"\\nFilled {column} nulls with median: {median_value:.2f} and created flag column\")\n",
    "        \n",
    "        # For categorical/object columns\n",
    "        else:\n",
    "            # If less than 5% missing, fill with mode\n",
    "            if missing_percent < 5:\n",
    "                mode_value = df_cleaned[column].mode()[0]\n",
    "                df_cleaned[column].fillna(mode_value, inplace=True)\n",
    "                print(f\"\\nFilled {column} nulls with mode: {mode_value}\")\n",
    "            # If more than 5% missing, create a new category for missing values\n",
    "            else:\n",
    "                df_cleaned[column].fillna('Missing', inplace=True)\n",
    "                print(f\"\\nFilled {column} nulls with 'Missing' category\")\n",
    "    \n",
    "    # Verify no missing values remain\n",
    "    remaining_nulls = df_cleaned.isnull().sum().sum()\n",
    "    print(f\"\\nRemaining null values after cleaning: {remaining_nulls}\")\n",
    "    \n",
    "    # Only create visualizations if there were missing values\n",
    "    if has_missing:\n",
    "        # Create better visualization of missing values before and after\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        \n",
    "        # First subplot - Before cleaning\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.heatmap(df.isnull(), \n",
    "                    yticklabels=False,\n",
    "                    cbar=True,\n",
    "                    cmap='YlOrRd',  \n",
    "                    center=0,       \n",
    "                    vmin=0,        \n",
    "                    vmax=1)        \n",
    "        plt.title('Missing Values Before Cleaning')\n",
    "        plt.xlabel('Columns')\n",
    "        \n",
    "        # Second subplot - After cleaning\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(df_cleaned.isnull(),\n",
    "                    yticklabels=False,\n",
    "                    cbar=True,\n",
    "                    cmap='YlOrRd',  \n",
    "                    center=0,       \n",
    "                    vmin=0,        \n",
    "                    vmax=1)        \n",
    "        plt.title('Missing Values After Cleaning')\n",
    "        plt.xlabel('Columns')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Add bar plot for missing values percentage\n",
    "        missing_cols = missing_percentages[missing_percentages > 0]\n",
    "        if not missing_cols.empty:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            missing_cols.plot(kind='bar')\n",
    "            plt.title('Percentage of Missing Values by Column')\n",
    "            plt.xlabel('Columns')\n",
    "            plt.ylabel('Percentage Missing')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # Display information about data types and memory usage\n",
    "    print(\"\\nDataset Information:\")\n",
    "    print(\"=\"*50)\n",
    "    print(df_cleaned.info())\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Apply the function to your dataset\n",
    "df_cleaned = analyze_and_handle_nulls(df)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df_cleaned.to_csv('cleaned_nutrients.csv', index=False)\n",
    "\n",
    "# Display shape information\n",
    "print(\"\\nShape of Original Dataset:\", df.shape)\n",
    "print(\"Shape of Cleaned Dataset:\", df_cleaned.shape)\n",
    "\n",
    "# Display sample of cleaned data\n",
    "print(\"\\nSample of Cleaned Data:\")\n",
    "print(\"=\"*50)\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ba606c-034e-4de4-b721-3fff9c617054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully!\n",
      "No missing values found in the dataset!\n",
      "\n",
      "Sample of Cleaned Data (First 3 Columns):\n",
      "      ID                       FoodGroup  \\\n",
      "0  16116     Legumes and Legume Products   \n",
      "1  18316                  Baked Products   \n",
      "2  15261  Finfish and Shellfish Products   \n",
      "3   8417               Breakfast Cereals   \n",
      "4  20022         Cereal Grains and Pasta   \n",
      "\n",
      "                                             Descrip  \n",
      "0                       Soy flour, full-fat, roasted  \n",
      "1        Pie, coconut custard, commercially prepared  \n",
      "2                                 Fish, tilapia, raw  \n",
      "3  Cereals, QUAKER, Instant Oatmeal, Banana Bread...  \n",
      "4               Cornmeal, degermed, enriched, yellow  \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'C:\\Users\\trejan\\Desktop\\GenoneDataset\\nutrients'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Save cleaned dataset\u001b[39;00m\n\u001b[0;32m     69\u001b[0m cleaned_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrejan\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGenoneDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnutrients\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcleaned_nutrients.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 70\u001b[0m \u001b[43mdf_cleaned\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaned dataset saved successfully at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcleaned_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'C:\\Users\\trejan\\Desktop\\GenoneDataset\\nutrients'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the file path correctly using raw string format\n",
    "file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\GenoneDataset\\nutrients\\train.csv\"\n",
    "\n",
    "# Check if file exists before proceeding\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "else:\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"File loaded successfully!\")\n",
    "\n",
    "    def analyze_and_handle_nulls(df):\n",
    "        \"\"\"\n",
    "        Analyze null values and handle them appropriately based on the nature of the data\n",
    "        \"\"\"\n",
    "        # Calculate percentage of missing values for each column\n",
    "        missing_counts = df.isnull().sum()\n",
    "        missing_percentages = (missing_counts / len(df)) * 100\n",
    "        \n",
    "        # Create a DataFrame for missing values analysis\n",
    "        missing_data = pd.DataFrame({\n",
    "            'Missing Count': missing_counts,\n",
    "            'Missing Percentage (%)': missing_percentages\n",
    "        })\n",
    "        missing_data = missing_data[missing_data['Missing Count'] > 0]  # Filter only columns with missing data\n",
    "\n",
    "        # Display missing values summary\n",
    "        if not missing_data.empty:\n",
    "            print(\"\\nMissing Values Analysis:\")\n",
    "            print(missing_data)\n",
    "        else:\n",
    "            print(\"No missing values found in the dataset!\")\n",
    "\n",
    "        # Handle missing values based on the type of data and percentage missing\n",
    "        df_cleaned = df.copy()\n",
    "        \n",
    "        for column in df_cleaned.columns:\n",
    "            missing_percent = missing_percentages[column]\n",
    "            \n",
    "            if missing_percent == 0:\n",
    "                continue\n",
    "                \n",
    "            # Handle numerical columns\n",
    "            if df_cleaned[column].dtype in ['int64', 'float64']:\n",
    "                median_value = df_cleaned[column].median()\n",
    "                df_cleaned[column].fillna(median_value, inplace=True)\n",
    "            \n",
    "            # Handle categorical columns\n",
    "            else:\n",
    "                df_cleaned[column].fillna(df_cleaned[column].mode()[0], inplace=True)\n",
    "\n",
    "        # Show cleaned data sample (only first three columns)\n",
    "        cleaned_sample = df_cleaned.iloc[:, :3].head()\n",
    "        print(\"\\nSample of Cleaned Data (First 3 Columns):\")\n",
    "        print(cleaned_sample)\n",
    "\n",
    "        return df_cleaned\n",
    "\n",
    "    # Apply function\n",
    "    df_cleaned = analyze_and_handle_nulls(df)\n",
    "\n",
    "    # Save cleaned dataset\n",
    "    cleaned_file_path = r\"C:\\Users\\trejan\\Desktop\\GenoneDataset\\nutrients\\cleaned_nutrients.csv\"\n",
    "    df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "    print(f\"Cleaned dataset saved successfully at {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63747ef8-7458-425e-ad24-fab97a50cf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset loaded successfully!\n",
      "\n",
      "\n",
      "Missing Values Analysis:\n",
      "==================================================\n",
      "╒═══════════════════════════╤═════════════════════════════════════════╕\n",
      "│ Missing Values Analysis   │ No missing values found in the dataset! │\n",
      "├───────────────────────────┼─────────────────────────────────────────┤\n",
      "│ Shape of Original Dataset │ (6894, 41)                              │\n",
      "├───────────────────────────┼─────────────────────────────────────────┤\n",
      "│ Shape of Cleaned Dataset  │ (6894, 41)                              │\n",
      "╘═══════════════════════════╧═════════════════════════════════════════╛\n",
      "\n",
      "Sample of Cleaned Data (Up to 'Food Group' Column):\n",
      "╒════╤═══════╤════════════════════════════════╕\n",
      "│    │    ID │ FoodGroup                      │\n",
      "╞════╪═══════╪════════════════════════════════╡\n",
      "│  0 │ 16116 │ Legumes and Legume Products    │\n",
      "├────┼───────┼────────────────────────────────┤\n",
      "│  1 │ 18316 │ Baked Products                 │\n",
      "├────┼───────┼────────────────────────────────┤\n",
      "│  2 │ 15261 │ Finfish and Shellfish Products │\n",
      "├────┼───────┼────────────────────────────────┤\n",
      "│  3 │  8417 │ Breakfast Cereals              │\n",
      "├────┼───────┼────────────────────────────────┤\n",
      "│  4 │ 20022 │ Cereal Grains and Pasta        │\n",
      "╘════╧═══════╧════════════════════════════════╛\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'C:\\Users\\trejan\\Desktop\\GenoneDataset\\nutrients'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Save cleaned dataset\u001b[39;00m\n\u001b[0;32m     65\u001b[0m cleaned_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrejan\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGenoneDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnutrients\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcleaned_nutrients.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 66\u001b[0m \u001b[43mdf_cleaned\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Cleaned dataset saved successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'C:\\Users\\trejan\\Desktop\\GenoneDataset\\nutrients'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\GenoneDataset\\nutrients\\train.csv\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "else:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"\\nDataset loaded successfully!\\n\")\n",
    "\n",
    "\n",
    "def analyze_and_handle_nulls(df):\n",
    "    \"\"\"\n",
    "    Analyze null values and handle them appropriately based on the nature of the data.\n",
    "    \"\"\"\n",
    "    # Calculate missing values\n",
    "    missing_counts = df.isnull().sum()\n",
    "    missing_percentages = (missing_counts / len(df)) * 100\n",
    "    missing_data = pd.DataFrame({\n",
    "        'Missing Count': missing_counts,\n",
    "        'Missing Percentage (%)': missing_percentages\n",
    "    })\n",
    "    missing_data = missing_data[missing_data['Missing Count'] > 0]  # Filter only columns with missing values\n",
    "\n",
    "    # Display missing values in tabular format\n",
    "    print(\"\\nMissing Values Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    if not missing_data.empty:\n",
    "        print(tabulate(missing_data, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "    else:\n",
    "        summary_table = [\n",
    "            [\"Missing Values Analysis\", \"No missing values found in the dataset!\"],\n",
    "            [\"Shape of Original Dataset\", df.shape],\n",
    "            [\"Shape of Cleaned Dataset\", df.shape]\n",
    "        ]\n",
    "        print(tabulate(summary_table, tablefmt=\"fancy_grid\"))\n",
    "\n",
    "    # Handle missing values\n",
    "    df_cleaned = df.copy()\n",
    "    for column in df_cleaned.columns:\n",
    "        if df_cleaned[column].isnull().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        if df_cleaned[column].dtype in ['int64', 'float64']:  # Numerical data\n",
    "            df_cleaned[column].fillna(df_cleaned[column].median(), inplace=True)\n",
    "        else:  # Categorical data\n",
    "            df_cleaned[column].fillna(df_cleaned[column].mode()[0], inplace=True)\n",
    "\n",
    "    # Show cleaned data sample up to \"Food Group\" column\n",
    "    cleaned_sample = df_cleaned.loc[:, :\"FoodGroup\"].head()\n",
    "    print(\"\\nSample of Cleaned Data (Up to 'Food Group' Column):\")\n",
    "    print(tabulate(cleaned_sample, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "# Apply function\n",
    "df_cleaned = analyze_and_handle_nulls(df)\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_file_path = r\"C:\\Users\\trejan\\Desktop\\GenoneDataset\\nutrients\\cleaned_nutrients.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"\\n✅ Cleaned dataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb794bb-0c31-4683-822e-4939f5a7d3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset loaded successfully!\n",
      "\n",
      "📊 Missing Values Analysis:\n",
      "==================================================\n",
      "╒═══════════════════════════╤══════════════════════════╕\n",
      "│ Metric                    │ Value                    │\n",
      "╞═══════════════════════════╪══════════════════════════╡\n",
      "│ Missing Values            │ No missing values found! │\n",
      "├───────────────────────────┼──────────────────────────┤\n",
      "│ Shape of Original Dataset │ (6894, 41)               │\n",
      "├───────────────────────────┼──────────────────────────┤\n",
      "│ Shape of Cleaned Dataset  │ (6894, 41)               │\n",
      "╘═══════════════════════════╧══════════════════════════╛\n",
      "\n",
      "📌 Sample of Cleaned Data:\n",
      "╒════╤═══════╤════════════════════════════════╕\n",
      "│    │    ID │ FoodGroup                      │\n",
      "╞════╪═══════╪════════════════════════════════╡\n",
      "│  0 │ 16116 │ Legumes and Legume Products    │\n",
      "├────┼───────┼────────────────────────────────┤\n",
      "│  1 │ 18316 │ Baked Products                 │\n",
      "├────┼───────┼────────────────────────────────┤\n",
      "│  2 │ 15261 │ Finfish and Shellfish Products │\n",
      "├────┼───────┼────────────────────────────────┤\n",
      "│  3 │  8417 │ Breakfast Cereals              │\n",
      "├────┼───────┼────────────────────────────────┤\n",
      "│  4 │ 20022 │ Cereal Grains and Pasta        │\n",
      "╘════╧═══════╧════════════════════════════════╛\n",
      "\n",
      "✅ Cleaned dataset saved successfully at: C:\\Users\\trejan\\Desktop\\cleaned_nutrients.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\GenoneDataset\\nutrients\\train.csv\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"❌ Error: File not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.columns = df.columns.str.strip()  # Remove spaces from column names\n",
    "print(\"\\n✅ Dataset loaded successfully!\")\n",
    "\n",
    "\n",
    "def analyze_and_handle_nulls(df):\n",
    "    \"\"\"\n",
    "    Analyze null values, handle them appropriately, and display results.\n",
    "    \"\"\"\n",
    "    # Calculate missing values\n",
    "    missing_counts = df.isnull().sum()\n",
    "    missing_percentages = (missing_counts / len(df)) * 100\n",
    "    missing_data = pd.DataFrame({\n",
    "        'Column Name': df.columns,\n",
    "        'Missing Count': missing_counts,\n",
    "        'Missing Percentage (%)': missing_percentages\n",
    "    })\n",
    "    missing_data = missing_data[missing_data['Missing Count'] > 0]  # Filter only columns with missing values\n",
    "\n",
    "    # Display missing values in tabular format\n",
    "    print(\"\\n📊 Missing Values Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    if not missing_data.empty:\n",
    "        print(tabulate(missing_data, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "    else:\n",
    "        summary_table = [\n",
    "            [\"Missing Values\", \"No missing values found!\"],\n",
    "            [\"Shape of Original Dataset\", df.shape],\n",
    "            [\"Shape of Cleaned Dataset\", df.shape]\n",
    "        ]\n",
    "        print(tabulate(summary_table, headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "    # Handle missing values\n",
    "    df_cleaned = df.copy()\n",
    "    for column in df_cleaned.columns:\n",
    "        if df_cleaned[column].isnull().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        if df_cleaned[column].dtype in ['int64', 'float64']:  # Numerical data\n",
    "            df_cleaned[column].fillna(df_cleaned[column].median(), inplace=True)\n",
    "        else:  # Categorical data\n",
    "            df_cleaned[column].fillna(df_cleaned[column].mode()[0], inplace=True)\n",
    "\n",
    "    # Dynamically check if \"Food Group\" exists before slicing\n",
    "    food_group_col = \"FoodGroup\"\n",
    "    if food_group_col in df_cleaned.columns:\n",
    "        cleaned_sample = df_cleaned.loc[:, :food_group_col].head()\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Column '{food_group_col}' not found! Displaying first few columns instead.\")\n",
    "        cleaned_sample = df_cleaned.iloc[:, :10].head()  # Show first 10 columns as fallback\n",
    "\n",
    "    print(\"\\n📌 Sample of Cleaned Data:\")\n",
    "    print(tabulate(cleaned_sample, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "# Apply function\n",
    "df_cleaned = analyze_and_handle_nulls(df)\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_file_path = r\"C:\\Users\\trejan\\Desktop\\cleaned_nutrients.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"\\n✅ Cleaned dataset saved successfully at:\", cleaned_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5043da-6504-4eee-96e8-c9d25f1a67fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset loaded successfully!\n",
      "\n",
      "📊 Missing Values Analysis:\n",
      "==================================================\n",
      "╭───────────────────────────┬──────────────────────────╮\n",
      "│ Metric                    │ Value                    │\n",
      "├───────────────────────────┼──────────────────────────┤\n",
      "│ Missing Values            │ No missing values found! │\n",
      "├───────────────────────────┼──────────────────────────┤\n",
      "│ Shape of Original Dataset │ (6894, 41)               │\n",
      "├───────────────────────────┼──────────────────────────┤\n",
      "│ Shape of Cleaned Dataset  │ (6894, 41)               │\n",
      "╰───────────────────────────┴──────────────────────────╯\n",
      "\n",
      "📌 Sample of Cleaned Data:\n",
      "╔════╦═══════╦════════════════════════════════╗\n",
      "║    ║    ID ║ FoodGroup                      ║\n",
      "╠════╬═══════╬════════════════════════════════╣\n",
      "║  0 ║ 16116 ║ Legumes and Legume Products    ║\n",
      "╠════╬═══════╬════════════════════════════════╣\n",
      "║  1 ║ 18316 ║ Baked Products                 ║\n",
      "╠════╬═══════╬════════════════════════════════╣\n",
      "║  2 ║ 15261 ║ Finfish and Shellfish Products ║\n",
      "╠════╬═══════╬════════════════════════════════╣\n",
      "║  3 ║  8417 ║ Breakfast Cereals              ║\n",
      "╠════╬═══════╬════════════════════════════════╣\n",
      "║  4 ║ 20022 ║ Cereal Grains and Pasta        ║\n",
      "╚════╩═══════╩════════════════════════════════╝\n",
      "\n",
      "✅ Cleaned dataset saved successfully at: C:\\Users\\trejan\\Desktop\\cleaned_nutrients.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define dataset path\n",
    "file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\GenoneDataset\\nutrients\\train.csv\"\n",
    "\n",
    "# Check if file exists before proceeding\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"❌ Error: File not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(file_path)\n",
    "df.columns = df.columns.str.strip()  # Remove spaces from column names\n",
    "print(\"\\n✅ Dataset loaded successfully!\")\n",
    "\n",
    "\n",
    "def analyze_and_handle_nulls(df):\n",
    "    \"\"\"\n",
    "    Analyze missing values, handle them, and display results in a well-formatted table.\n",
    "    \"\"\"\n",
    "    # Calculate missing values\n",
    "    missing_counts = df.isnull().sum()\n",
    "    missing_percentages = (missing_counts / len(df)) * 100\n",
    "    missing_data = pd.DataFrame({\n",
    "        'Column Name': df.columns,\n",
    "        'Missing Count': missing_counts,\n",
    "        'Missing Percentage (%)': missing_percentages\n",
    "    })\n",
    "    missing_data = missing_data[missing_data['Missing Count'] > 0]  # Keep only columns with missing values\n",
    "\n",
    "    # Display missing values analysis\n",
    "    print(\"\\n📊 Missing Values Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    if not missing_data.empty:\n",
    "        print(tabulate(missing_data, headers=\"keys\", tablefmt=\"rounded_grid\"))\n",
    "    else:\n",
    "        summary_table = [\n",
    "            [\"Missing Values\", \"No missing values found!\"],\n",
    "            [\"Shape of Original Dataset\", df.shape],\n",
    "            [\"Shape of Cleaned Dataset\", df.shape]\n",
    "        ]\n",
    "        print(tabulate(summary_table, headers=[\"Metric\", \"Value\"], tablefmt=\"rounded_grid\"))\n",
    "\n",
    "    # Handling missing values\n",
    "    df_cleaned = df.copy()\n",
    "    for column in df_cleaned.columns:\n",
    "        if df_cleaned[column].isnull().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        if df_cleaned[column].dtype in ['int64', 'float64']:  # Numerical columns\n",
    "            df_cleaned[column].fillna(df_cleaned[column].median(), inplace=True)\n",
    "        else:  # Categorical columns\n",
    "            df_cleaned[column].fillna(df_cleaned[column].mode()[0], inplace=True)\n",
    "\n",
    "    # Dynamically check if \"Food Group\" exists before displaying\n",
    "    food_group_col = \"FoodGroup\"\n",
    "    if food_group_col in df_cleaned.columns:\n",
    "        cleaned_sample = df_cleaned.loc[:, :food_group_col].head()\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Column '{food_group_col}' not found! Displaying first few columns instead.\")\n",
    "        cleaned_sample = df_cleaned.iloc[:, :10].head()  # Show first 10 columns as fallback\n",
    "\n",
    "    print(\"\\n📌 Sample of Cleaned Data:\")\n",
    "    print(tabulate(cleaned_sample, headers=\"keys\", tablefmt=\"double_grid\"))\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "# Apply function\n",
    "df_cleaned = analyze_and_handle_nulls(df)\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_file_path = r\"C:\\Users\\trejan\\Desktop\\cleaned_nutrients.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"\\n✅ Cleaned dataset saved successfully at:\", cleaned_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c699c491-3c76-4bb2-9e18-0bc6695197bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset loaded successfully!\n",
      "\n",
      "📊 Missing Values Analysis:\n",
      "==================================================\n",
      "╭────┬──────────────────┬──────────────────────────╮\n",
      "│    │ Metric           │ Value                    │\n",
      "├────┼──────────────────┼──────────────────────────┤\n",
      "│  0 │ Missing Values   │ No missing values found! │\n",
      "├────┼──────────────────┼──────────────────────────┤\n",
      "│  1 │ Shape of Dataset │ (6894, 41)               │\n",
      "╰────┴──────────────────┴──────────────────────────╯\n",
      "\n",
      "📌 Sample of Cleaned Data:\n",
      "╔════╦═══════╦════════════════════════════════╗\n",
      "║    ║    ID ║ FoodGroup                      ║\n",
      "╠════╬═══════╬════════════════════════════════╣\n",
      "║  0 ║ 16116 ║ Legumes and Legume Products    ║\n",
      "╠════╬═══════╬════════════════════════════════╣\n",
      "║  1 ║ 18316 ║ Baked Products                 ║\n",
      "╠════╬═══════╬════════════════════════════════╣\n",
      "║  2 ║ 15261 ║ Finfish and Shellfish Products ║\n",
      "╠════╬═══════╬════════════════════════════════╣\n",
      "║  3 ║  8417 ║ Breakfast Cereals              ║\n",
      "╠════╬═══════╬════════════════════════════════╣\n",
      "║  4 ║ 20022 ║ Cereal Grains and Pasta        ║\n",
      "╚════╩═══════╩════════════════════════════════╝\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trejan\\AppData\\Local\\Temp\\ipykernel_8600\\3833500618.py:95: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(image_path, dpi=300, bbox_inches=\"tight\", pad_inches=0.2)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Temp\\ipykernel_8600\\3833500618.py:95: UserWarning: Glyph 128204 (\\N{PUSHPIN}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(image_path, dpi=300, bbox_inches=\"tight\", pad_inches=0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🖼️ Tables saved as an image at: C:\\Users\\trejan\\Desktop\\cleaned_data_tables.png\n",
      "\n",
      "✅ Cleaned dataset saved successfully at: C:\\Users\\trejan\\Desktop\\cleaned_nutrients.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define dataset path\n",
    "file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\GenoneDataset\\nutrients\\train.csv\"\n",
    "\n",
    "# Check if file exists before proceeding\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"❌ Error: File not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(file_path)\n",
    "df.columns = df.columns.str.strip()  # Remove spaces from column names\n",
    "print(\"\\n✅ Dataset loaded successfully!\")\n",
    "\n",
    "\n",
    "def analyze_and_handle_nulls(df):\n",
    "    \"\"\"\n",
    "    Analyze missing values, handle them, display results, and save as PNG.\n",
    "    \"\"\"\n",
    "    # Calculate missing values\n",
    "    missing_counts = df.isnull().sum()\n",
    "    missing_percentages = (missing_counts / len(df)) * 100\n",
    "    missing_data = pd.DataFrame({\n",
    "        'Column Name': df.columns,\n",
    "        'Missing Count': missing_counts,\n",
    "        'Missing Percentage (%)': missing_percentages\n",
    "    })\n",
    "\n",
    "    # If no missing values, create a placeholder summary table\n",
    "    if missing_data[\"Missing Count\"].sum() == 0:\n",
    "        missing_data = pd.DataFrame({\n",
    "            \"Metric\": [\"Missing Values\", \"Shape of Dataset\"],\n",
    "            \"Value\": [\"No missing values found!\", str(df.shape)]\n",
    "        })\n",
    "\n",
    "    # Display missing values analysis\n",
    "    print(\"\\n📊 Missing Values Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(tabulate(missing_data, headers=\"keys\", tablefmt=\"rounded_grid\"))\n",
    "\n",
    "    # Handling missing values\n",
    "    df_cleaned = df.copy()\n",
    "    for column in df_cleaned.columns:\n",
    "        if df_cleaned[column].isnull().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        if df_cleaned[column].dtype in ['int64', 'float64']:  # Numerical columns\n",
    "            df_cleaned[column].fillna(df_cleaned[column].median(), inplace=True)\n",
    "        else:  # Categorical columns\n",
    "            df_cleaned[column].fillna(df_cleaned[column].mode()[0], inplace=True)\n",
    "\n",
    "    # Dynamically check if \"Food Group\" exists before displaying\n",
    "    food_group_col = \"FoodGroup\"\n",
    "    if food_group_col in df_cleaned.columns:\n",
    "        cleaned_sample = df_cleaned.loc[:, :food_group_col].head()\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Column '{food_group_col}' not found! Displaying first few columns instead.\")\n",
    "        cleaned_sample = df_cleaned.iloc[:, :10].head()  # Show first 10 columns as fallback\n",
    "\n",
    "    print(\"\\n📌 Sample of Cleaned Data:\")\n",
    "    print(tabulate(cleaned_sample, headers=\"keys\", tablefmt=\"double_grid\"))\n",
    "\n",
    "    # Save tables as PNG\n",
    "    save_tables_as_image(missing_data, cleaned_sample)\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def save_tables_as_image(missing_data, cleaned_sample):\n",
    "    \"\"\"\n",
    "    Generate and save an image with both missing values and cleaned data tables.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Convert tables to string format\n",
    "    missing_text = tabulate(missing_data, headers=\"keys\", tablefmt=\"grid\")\n",
    "    cleaned_text = tabulate(cleaned_sample, headers=\"keys\", tablefmt=\"grid\")\n",
    "\n",
    "    # Combine both tables\n",
    "    full_text = f\"📊 Missing Values Analysis:\\n{missing_text}\\n\\n📌 Sample of Cleaned Data:\\n{cleaned_text}\"\n",
    "\n",
    "    # Add text to figure\n",
    "    ax.text(0.05, 0.95, full_text, fontsize=10, verticalalignment=\"top\", fontfamily=\"monospace\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Save image\n",
    "    image_path = r\"C:\\Users\\trejan\\Desktop\\cleaned_data_tables.png\"\n",
    "    plt.savefig(image_path, dpi=300, bbox_inches=\"tight\", pad_inches=0.2)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\n🖼️ Tables saved as an image at: {image_path}\")\n",
    "\n",
    "\n",
    "# Apply function\n",
    "df_cleaned = analyze_and_handle_nulls(df)\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_file_path = r\"C:\\Users\\trejan\\Desktop\\cleaned_nutrients.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"\\n✅ Cleaned dataset saved successfully at:\", cleaned_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
